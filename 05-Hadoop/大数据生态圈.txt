数据处理工具
1、数据来源
    Oracle
    MySQL
    HBase
    日志数据
    ...

2、数据采集
    Sqoop
    DataX
    Flume

3、数据传输
    Sqoop
    DataX
    Kafka

4、数据存储
    HDFS
        NoSQL
    HBase
        列式数据库
    Kafka

5、资源管理
    YARN


6、数据计算
    MapReduce
    Spark
    Flink

7、数据查询
    Hive
    Spark
    Tez
    Presto
    Impala

8、数据同步
    Spoop
    DataX

9、数据分析(OLAP)
    Kylin
    ClickHouse
    ElasticSearch

10、数据展示(BI)
    帆软
    Cognos

11、作业调度
    Oozie
    Zookeeper



一、数据来源层
1.1、数据库(结构化数据)
1.2、文件日志(半结构化数据)
1.3、视频、ppt等(非结构化数据)

二、数据传输层
2.1、Sqoop数据传输: 结构化数据
2.2、Flume日志采集: 半结构化数据
2.3、Kafka消息队列: 各类数据

三、数据存储层
3.1、HDFS文件存储
3.2、HBase列式数据库
3.3、Kafka消息队列

四、资源管理层
4.1、YARN资源管理

五、数据计算层
5.1、MapReduce离线计算: Hive数据查询
5.2、Spark Core内存计算
    Spark Mlib数据挖掘
    Spark Sql数据查询
    Spark Streaming实时计算
5.3、Flink实时计算
5.4、Storm实时计算

六、任务调度层
6.1、Oozie任务调度
6.2、Azkaban任务调度

七、业务模型层
7.1、业务模型
7.2、数据可视化
7.3、业务应用

7.4、多维分析OLAP

7.4.1、OLAP技术分类
OLAP分类
    1、ROLAP：关系型联机实时分析系统
    2、MOLAP：多维联机实时分析系统
    3、HOLAP：混合型联机实时分析系统

ROLAP：关系型联机实时分析系统
    1、ROLAP介绍
        ROLAP的核心依赖于关系型数据库，允许用户使用维度模型进行数据分析，将纬度值存储在维度表中，将度量值存储在事实表中，通过关系型数据块访问数据，使用SQL进行查询分析
    2、使用模式
        根据用户的需求，对不同维度进行分析后，将分析数据导入到另外一张数据库表中，供用户查询使用
    2、ROLAP优势
        1) 处理高基数列具有更好的扩展性
        2) 擅长处理非聚合类的原始数据，生态圈内用于原始数据入库的ETL工具众多，同时比MOLAP入库速率更高
        3) 由于数据存储在关系型数据库中，所以支持标准SQL接口
    3、ROLAP劣势
        1) 不擅长处理已聚合的数据(待确认)
        2) ROLAP的性能很大程度上依赖于使用的关系型数据库的查询和缓存性能


MOLAP：多维联机实时分析系统
    1、MOLAP介绍
        MOLAP是OLAP的经典使用模式。MOLAP和ROLAP都可以使用维度模型进行数据分析，但是MOLAP并不将数据存储在维度表或者事实表中，而是对原始数据进行预计算(比如聚合操作)，将计算结果存储在OLAP Cube中。
    2、MOLAP优势
        MOLAP不采用关系型数据库进行数据存储，所以必须采用特殊的存储手段，例如：压缩存储、索引、以及缓存技术等
    3、MOLAP劣势
        1) 数据导入较慢，需要使用定制的ETL入库工具
        2) 由于没有维度表和事实表，所以对于更新操作以及明显查询，效率要比ROLAP低很多。

HOLAP：混合型联机实时分析系统
    1、HOLAP介绍
        HOLAP利用了ROLAP与MOLAP的各自优势。
        从纵向角度，即允许用户将部分数据(比如聚合类数据)使用MOLAP进行存储，从而获得更快的查询性能。有允许不部分数据(比如原始数据)使用ROLAP进行存储，使用户能够查看细粒度数据。
        从横向角度，使用MOLAP存储最近较热的数据，从而提升查询性能；使用ROLAP存储历史较冷的数据。

7.4.2、kylin
Kylin介绍
    Apache Kylin是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析(OLAP)能力以支持超大规模数据。能在亚秒查询巨量的Hive表。

Kylin架构
    1) 数据源: Hadoop,Hive,Kafka,RDBMS
        支持通过Kylin进行OLAP分析的数据源
    2) Cube构建引擎(任务引擎): Cube Build Engine
        这套引擎的设计目的在于处理所有离线任务，其中包括Shell脚本、Java API以及Map Reduce任务等。
        任务引擎对Kylin当中的全部任务加以管理与协调，从而确保每一项任务都能得到切实执行并解决其间出现的故障。
    3) 元数据管理工具(元数据): Metadata
        Kylin是一款元数据驱动型应用程序。元数据管理工具是一大关键性组件，用于对保存在Kylin当中的所有元数据进行管理，其中包括最为重要的cube元数据。
        其它全部组件的正常运作都需以元数据管理工具为基础。Kylin的元数据存储在HBase中。
    4) 路由器(路由层)(默认关闭): Routing
        最初设计时曾考虑过将Kylin不能执行的查询引导去Hive中继续执行，但在实践后发现Hive与Kylin的速度差异过大，导致用户无法对查询的速度有一致的期望，很可能大多数查询几秒内就返回结果了，而有些查询则要等几分钟到几十分钟，因此体验非常糟糕。最后这个路由功能在发行版中默认关闭。
    5) 数据存储: HBase/OLAP Cube
        Kylin预处理号的Cube模型数据存储在HBase中
    6) 查询引擎(查询引擎层): Query Engine
        当Cube准备就绪后，查询引擎就能够获取并解析用户查询。它随后会与系统中的其它组件进行交互，从而向用户返回对应的结果。
    7) REST服务层: REST Server
        REST Server是一套面向应用程序开发的入口点，旨在实现针对Kylin平台的应用开发工作。此类应用程序可以提供查询、获取结果、触发cube构建任务、获取元数据以及获取用户权限等等。另外可以通过Restful接口实现SQL查询。
    8) 应用层: Web APP/REST API, BI Tools/JDBC/ODBC
        应用程序调度
        BI工具数据查询

Kylin特点
    1) 支持标准SQL接口
    2) 支持超大规模数据集
    3) 亚秒级相应
    4) 可伸缩性和高吞吐率
    5) BI工具集成

Kylin使用
    1) 创建工程
    2) 获取数据源: Hive表,Spark表...
    3) 创建Model
        (1) 填写Model信息
        (2) 指定事实表
        (3) 选择维度表
        (4) 指定事实表和维度表的关联条件
        (5) 指定维度字段
        (6) 指定度量字段
        (7) 指定事实表分区字段(仅支持时间分区)
    4) 构建Cube
        (1) 填写Cube信息，选择Cube所依赖的Model
        (2) 选择所需的维度
        (3) 选择所需度量值
        (4) Cube自动合并设置
            Cube需按照日期分区字段每天进行构建，每次构建的结果会保存在HBase中的一张表中，为提高查询效率，需将每日的Cube进行合并，此处可设置合并周期。
        (5) Kylin高级配置(Cube优化)
        (6) Kylin相关属性配置覆盖
        (7) Cube信息总览(Cube创建完成)
        (8) 构建Cube(计算)
        (9) 选择要构建的时间区间
        (10) 查看构建进度
    注意：
        Kylin不能处理Hive表中的复杂数据类型(Array,Map,Struct)，即便复杂类型的字段并未参与到计算之中。因此在加载Hive数据源时，不能直接加载带有复杂数据类型字段的表。需要将复杂数据类型处理掉以后才能加载。

Kylin Cube构建原理
    https://blog.csdn.net/qq_64557330/article/details/126916150?spm=1001.2014.3001.5502
    1) 维度：观察数据的角度
    2) 度量：被聚合(观察)的统计值，也就是聚合运算的结果
    3) Cube和Cuboid：根据维度和度量做预计算的Cube理论
        给定一个数据模型，可以对其上的所有维度进行聚合，对于N个维度来说，组合的所有可能性共有2^n种(2的n次方)。
        对于每一种维度的组合，将度量值做聚合计算，然后将结果保存为一个物化视图，称为Cuboid。所有维度组合的Cuboid作为一个整体，称为Cube
        样例：有四个维度字段，Cuboid个数：零维度(0D)|1个,一维度(1D)|4个,二维度(2D)|4*3/2=6个,三维度(3D)|4个,四维度(4D)|1个
    4) Cube构建算法
        (1) 逐层构建算法(layer)
            i  ) 一个N维的Cube，是由1个N维子立方体、N个(N-1)维子立方体、N*(N-1)/2个(N-2)位子立方体、...、N个1维子立方体、1个0维子立方体构成，总共2^N个子立方体构成。
            ii ) 逐层构建算法：按维度数逐层减少来计算，每个层级的计算(除了第一层，它是从原始数据聚合而来)，是基于它上一层的结果来计算的。
            iii) 每一轮的就算都是一个MapReduce任务，且串行执行；一个N维的Cube，至少需要N次MapReduce Job
            iv ) 算法优点：
                a) 此算法充分利用了MapReduce的优点，处理了中间复杂的排序和shuffle工作，故而算法代码清晰简单，易于维护。
                b) 受益于Hadoop的日趋成熟，此算法非常稳定，即便是集群资源紧张时，也能保证最终能够完成。
            v  ) 算法缺点：
                a) 当Cube有比较多维度的时候，所需要的MapReduce任务也相应增加；由于Hadoop的任务调度需要耗费额外资源，特别是集群较庞大的时候，反复递交任务造成的额外开销会相当可观。
                b) 由于Mapper逻辑中并未进行聚合操作，所以每轮MR的shuffle工作量都很大，导致效率低下。
                c) 对HDFS的读写操作较多。由于每一层计算的输出会用做下一层计算的输入，这些Key-Value需要写到HDFS上；当所有计算都完成后，Kylin还需要额外的一轮任务将这些文件转成HBase的HFile格式，以导入到HBase中去。
                d) 总结：该算法的效率较低，尤其是当Cube维度数较大的时候。

        (2) 快速构建算法(inmem)
            i  ) 也称为 逐段(By Segment)或逐块(By Split)算法。
            ii ) 主要思想：
                a) 每个Mapper将其所分配到的数据块，计算成一个完整的小Cube段(包含所有Cuboid)。
                b) 每个Mapper将计算完的Cube段输出给Reducer做合并，生成大Cube，也就是最终结果。
            iii) 与逐层构建法有两点不同：
                a) Mapper会利用内存做预聚合，算出所有组合；Mapper输出的每个Key都是不同的，这样会减少输出到Hadoop MapReduce的数据量，Combiner也不再需要。
                b) 一轮MapReduce便会完成所有层次的计算，减少Hadoop任务的调配。


Kylin Cube存储原理

Kylin Cube构建优化
    1) 使用衍生维度：在有效维度内将维度表的非主键维度排除掉，使用维度表的主键维度替代。Kylin在底层记录维度表主键与维度表其他维度之间的映射关系，在查询是动态的将维度表的主键转换成非主键维度，并进行实时聚合(但是如果聚合工作量很大，不建议使用衍生维度)。
    2) 使用聚合组：将Cube的所有维度按组划分，每个业务需求提供一组Cube维度，也就是提供一组Cuboid。所有Cuboid的组合就是Cube需要构建的Cuboid集
    3) 聚合组-强制维度：某个维度如果在所有组中都需要存在，那么可以定义为强制维度，在Cube构建的时候每组Cuboid都有该字段，这样就能减少一半的Cuboid数量
    4) 聚合组-层级维度：如果维度中的几个维度有层级关系，可以把这些维度定义为层级维度，在Cube构建的时候，就会按层级进行组合。可以减少Cuboid数量
    5) 聚合组联合维度：某几个维度有内在关系，要么一起出现，要么都不出现，那么就可以将这些维度定义为联合维度。能减少很多的Cuboid。
    6) RowKey优化：设计良好的RowKey将更有效地完成数据的查询过滤和定位，减少IO次数，提高查询速度。

7.4.3、ClickHouse
7.4.4、ElasticSearch
    
7.5、即席查询

7.5.1、Presto
Presto介绍
    Presto是一个开源的分布式SQL查询引擎，数据量支持GB到PB字节，主要用来处理秒级查询的场景

Presto架构

Presto优缺点
    1) Presto优点
        (1) Presto基于内存运算，减少了硬盘IO，计算更快
        (2) 能够连接多个数据源，跨数据源连表查询，如从Hive查询大量网站访问记录，然后从MySQL中匹配出设备信息
    
    2) Presto缺点
        Presto能够处理PB级别的海量数据分析，但是Presto并不是把PB级数据都放在内存中计算的。而是根据场景，如Count，avg等聚合运算，是边读数据边计算，再清内存，再读数据再计算，这种耗的内存并不高。但是连表查询，就可能产生大量的临时数据，因此速度会变慢

7.5.2、Impala


7.5.3、Presto与Impala性能比较
    Impala性能稍领先于Presto，但是Presto在数据源支持上非常丰富，包括Hive、图数据库、传统关系型数据块、Redis等
